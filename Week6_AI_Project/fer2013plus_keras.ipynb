{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Physical GPUs, 2 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/python\n",
    "import tensorflow as tf\n",
    " \n",
    " \n",
    " \n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)\n",
    "\n",
    "import keras\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# read all dataset for training\n",
    "#------------------------------------------------------------------------------\n",
    "traindir = '/home/piai/Desktop/ferplus/FER2013Train/'\n",
    "d_ = {}\n",
    "maxnum = 0\n",
    "for i in range(8):\n",
    "    fname = '/home/piai/Desktop/ferplus/ferplus_keras_labe/train-ori-c%d.txt' % (i)\n",
    "    f = open(fname)\n",
    "    alllines = f.readlines()\n",
    "    f.close()\n",
    "    if maxnum < len(alllines):\n",
    "        maxnum = len(alllines)\n",
    "    ##\n",
    "    d_[i] = alllines\n",
    "##\n",
    "##\n",
    "x_train = np.zeros((maxnum*8, 64, 64, 1), dtype='f')\n",
    "x_p = np.zeros((maxnum*8, 64, 64, 1), dtype='f')\n",
    "y_p = np.zeros((maxnum*8), dtype=np.uint8)\n",
    "\n",
    "idxout = 0\n",
    "for i in range(8):\n",
    "    data = d_[i]\n",
    "    num = 0\n",
    "    idx = 0    \n",
    "    while num < maxnum:\n",
    "        sp = (data[idx]).split(\" \")\n",
    "        y_p[idxout ] = int(sp[1])\n",
    "        img = cv2.imread(os.path.join(traindir, sp[0]), cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.resize(img, (64,64))\n",
    "        x_p[idxout, :, :, 0] = img\n",
    "        ###\n",
    "        idxout = idxout + 1\n",
    "        idx = idx + 1\n",
    "        if idx >= len(data):\n",
    "            idx = 0\n",
    "        num = num + 1\n",
    "    ###\n",
    "###\n",
    "\n",
    "randomid = np.random.permutation(x_p.shape[0])\n",
    "y_p = keras.utils.to_categorical(y_p, num_classes=8)\n",
    "y_train = np.zeros(y_p.shape, dtype=np.uint8)\n",
    "for i in range(x_p.shape[0]):\n",
    "    x_train[i, :, :, :] = x_p[randomid[i], :, :, :].copy()\n",
    "    y_train[i] = y_p[randomid[i]]\n",
    "x_p = 0\n",
    "#------------------------------------------------------------------------------\n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# read all dataset for validation\n",
    "#------------------------------------------------------------------------------\n",
    "valdir = '/home/piai/Desktop/ferplus/FER2013Valid/'\n",
    "f = open('/home/piai/Desktop/ferplus/ferplus_keras_labe/validation.txt')\n",
    "alllines = f.readlines()\n",
    "f.close()\n",
    "\n",
    "x_val = np.zeros((len(alllines), 64, 64, 1), dtype='f')\n",
    "y_p = np.zeros((len(alllines)), dtype=np.uint8)\n",
    "\n",
    "idx = 0\n",
    "for line in alllines:\n",
    "    sp = line.split(\" \")\n",
    "    y_p[idx] = int(sp[1])\n",
    "    img = cv2.imread(os.path.join(valdir, sp[0]), cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, (64,64))\n",
    "    x_val[idx, :, :, 0] = img\n",
    "    idx = idx + 1\n",
    "###\n",
    "\n",
    "y_val = keras.utils.to_categorical(y_p, num_classes=8)\n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# Model defenition\n",
    "#------------------------------------------------------------------------------\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "### data augmentation\n",
    "datagen = ImageDataGenerator(featurewise_center=True, \n",
    "                             featurewise_std_normalization=True, \\\n",
    "                             width_shift_range=0.08, \\\n",
    "                             height_shift_range=0.08, \\\n",
    "                             zoom_range=0.05, \\\n",
    "                             rotation_range=20, \\\n",
    "                             shear_range=0.05, \\\n",
    "                             horizontal_flip=True)\n",
    "\n",
    "### model description\n",
    "vgg13 = keras.models.Sequential()\n",
    "\n",
    "vgg13.add(keras.layers.Conv2D(64, (3, 3), activation='relu', \n",
    "                              input_shape=(64,64,1), padding='same'))\n",
    "vgg13.add(keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "vgg13.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "vgg13.add(keras.layers.Dropout(0.25))\n",
    "\n",
    "vgg13.add(keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "vgg13.add(keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "vgg13.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "vgg13.add(keras.layers.Dropout(0.25))\n",
    "\n",
    "vgg13.add(keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "vgg13.add(keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "vgg13.add(keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "vgg13.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "vgg13.add(keras.layers.Dropout(0.25))\n",
    "\n",
    "vgg13.add(keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "vgg13.add(keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "vgg13.add(keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "vgg13.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "vgg13.add(keras.layers.Dropout(0.25))\n",
    "\n",
    "vgg13.add(keras.layers.Flatten())\n",
    "vgg13.add(keras.layers.Dense(1024, activation='relu'))\n",
    "vgg13.add(keras.layers.Dropout(0.5))\n",
    "\n",
    "vgg13.add(keras.layers.Dense(1024, activation='relu'))\n",
    "vgg13.add(keras.layers.Dropout(0.5))\n",
    "\n",
    "vgg13.add(keras.layers.Dense(8, activation='softmax'))\n",
    "#------------------------------------------------------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73144, 64, 64, 1)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-f9f7d110ce14>:27: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 0.025.\n",
      "Epoch 1/100\n",
      "572/571 [==============================] - ETA: 0s - loss: 2.0479 - accuracy: 0.1620WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "572/571 [==============================] - 107s 187ms/step - loss: 2.0479 - accuracy: 0.1620 - val_loss: 1.9353 - val_accuracy: 0.2271 - lr: 0.0250\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 0.02475.\n",
      "Epoch 2/100\n",
      "571/571 [============================>.] - ETA: 0s - loss: 1.8016 - accuracy: 0.2867WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "572/571 [==============================] - 43s 75ms/step - loss: 1.8014 - accuracy: 0.2867 - val_loss: 1.7015 - val_accuracy: 0.2234 - lr: 0.0247\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 0.0245.\n",
      "Epoch 3/100\n",
      "571/571 [============================>.] - ETA: 0s - loss: 1.4251 - accuracy: 0.4582WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "572/571 [==============================] - 43s 75ms/step - loss: 1.4250 - accuracy: 0.4582 - val_loss: 1.3228 - val_accuracy: 0.4653 - lr: 0.0245\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to 0.02425.\n",
      "Epoch 4/100\n",
      "571/571 [============================>.] - ETA: 0s - loss: 1.0897 - accuracy: 0.5950WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "572/571 [==============================] - 43s 76ms/step - loss: 1.0897 - accuracy: 0.5950 - val_loss: 1.0612 - val_accuracy: 0.5870 - lr: 0.0243\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to 0.024.\n",
      "Epoch 5/100\n",
      "571/571 [============================>.] - ETA: 0s - loss: 0.8596 - accuracy: 0.6845WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "572/571 [==============================] - 49s 85ms/step - loss: 0.8595 - accuracy: 0.6846 - val_loss: 0.9363 - val_accuracy: 0.6419 - lr: 0.0240\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to 0.02375.\n",
      "Epoch 6/100\n",
      "571/571 [============================>.] - ETA: 0s - loss: 0.7082 - accuracy: 0.7417WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "572/571 [==============================] - 50s 88ms/step - loss: 0.7083 - accuracy: 0.7416 - val_loss: 0.8550 - val_accuracy: 0.6824 - lr: 0.0237\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to 0.0235.\n",
      "Epoch 7/100\n",
      "571/571 [============================>.] - ETA: 0s - loss: 0.6069 - accuracy: 0.7772WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "572/571 [==============================] - 51s 89ms/step - loss: 0.6068 - accuracy: 0.7773 - val_loss: 0.7680 - val_accuracy: 0.7183 - lr: 0.0235\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to 0.02325.\n",
      "Epoch 8/100\n",
      "571/571 [============================>.] - ETA: 0s - loss: 0.5353 - accuracy: 0.8064WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "572/571 [==============================] - 50s 88ms/step - loss: 0.5352 - accuracy: 0.8065 - val_loss: 0.7152 - val_accuracy: 0.7298 - lr: 0.0233\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to 0.023000000000000003.\n",
      "Epoch 9/100\n",
      "571/571 [============================>.] - ETA: 0s - loss: 0.4864 - accuracy: 0.8233WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "572/571 [==============================] - 50s 87ms/step - loss: 0.4864 - accuracy: 0.8233 - val_loss: 0.7559 - val_accuracy: 0.7107 - lr: 0.0230\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to 0.022750000000000003.\n",
      "Epoch 10/100\n",
      "571/571 [============================>.] - ETA: 0s - loss: 0.4433 - accuracy: 0.8384WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "572/571 [==============================] - 50s 88ms/step - loss: 0.4433 - accuracy: 0.8384 - val_loss: 0.6167 - val_accuracy: 0.7796 - lr: 0.0227\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to 0.022500000000000003.\n",
      "Epoch 11/100\n",
      "571/571 [============================>.] - ETA: 0s - loss: 0.4107 - accuracy: 0.8511WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "572/571 [==============================] - 51s 89ms/step - loss: 0.4108 - accuracy: 0.8510 - val_loss: 0.6000 - val_accuracy: 0.7856 - lr: 0.0225\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to 0.022250000000000002.\n",
      "Epoch 12/100\n",
      "571/571 [============================>.] - ETA: 0s - loss: 0.3811 - accuracy: 0.8628WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "572/571 [==============================] - 51s 89ms/step - loss: 0.3811 - accuracy: 0.8628 - val_loss: 0.6290 - val_accuracy: 0.7693 - lr: 0.0223\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to 0.022000000000000002.\n",
      "Epoch 13/100\n",
      "571/571 [============================>.] - ETA: 0s - loss: 0.3584 - accuracy: 0.8700WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "572/571 [==============================] - 51s 89ms/step - loss: 0.3584 - accuracy: 0.8700 - val_loss: 0.5657 - val_accuracy: 0.8019 - lr: 0.0220\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to 0.021750000000000002.\n",
      "Epoch 14/100\n",
      "571/571 [============================>.] - ETA: 0s - loss: 0.3442 - accuracy: 0.8755WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "572/571 [==============================] - 51s 88ms/step - loss: 0.3442 - accuracy: 0.8755 - val_loss: 0.6106 - val_accuracy: 0.7736 - lr: 0.0217\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to 0.021500000000000002.\n",
      "Epoch 15/100\n",
      "571/571 [============================>.] - ETA: 0s - loss: 0.3243 - accuracy: 0.8824WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "572/571 [==============================] - 51s 88ms/step - loss: 0.3244 - accuracy: 0.8823 - val_loss: 0.5833 - val_accuracy: 0.7850 - lr: 0.0215\n",
      "\n",
      "Epoch 00016: LearningRateScheduler reducing learning rate to 0.02125.\n",
      "Epoch 16/100\n",
      "571/571 [============================>.] - ETA: 0s - loss: 0.3092 - accuracy: 0.8886WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "572/571 [==============================] - 49s 86ms/step - loss: 0.3092 - accuracy: 0.8886 - val_loss: 0.5903 - val_accuracy: 0.7908 - lr: 0.0213\n",
      "\n",
      "Epoch 00017: LearningRateScheduler reducing learning rate to 0.021.\n",
      "Epoch 17/100\n",
      "571/571 [============================>.] - ETA: 0s - loss: 0.2958 - accuracy: 0.8925WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "572/571 [==============================] - 45s 78ms/step - loss: 0.2959 - accuracy: 0.8924 - val_loss: 0.5975 - val_accuracy: 0.7850 - lr: 0.0210\n",
      "\n",
      "Epoch 00018: LearningRateScheduler reducing learning rate to 0.02075.\n",
      "Epoch 18/100\n",
      "316/571 [===============>..............] - ETA: 18s - loss: 0.2827 - accuracy: 0.8971"
     ]
    }
   ],
   "source": [
    "#------------------------------------------------------------------------------\n",
    "# Training Process\n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "def steplr(epoch):\n",
    "    lr = 0.025\n",
    "    max_epochs=100.0\n",
    "    lr = lr * (1.0 - epoch/max_epochs)\n",
    "    return lr\n",
    "\n",
    "sgd = keras.optimizers.SGD(lr=0.025, decay=0.0005, momentum=0.9, nesterov=True)\n",
    "vgg13.compile(loss='categorical_crossentropy', optimizer=sgd,  \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history= datagen.fit(x_train)\n",
    "\n",
    "gen =vgg13.fit_generator(datagen.flow(x_train, y_train, batch_size=128), \n",
    "                    steps_per_epoch=x_train.shape[0]/128, \n",
    "                    epochs=100, \n",
    "                    validation_data=datagen.flow(x_val, y_val, batch_size=128),\n",
    "                    validation_steps=x_val.shape[0]/128,\n",
    "                    callbacks=[\n",
    "                        keras.callbacks.LearningRateScheduler(steplr, verbose=1),\n",
    "                        keras.callbacks.ModelCheckpoint('vgg13-baseline.h5', \n",
    "                            monitor='val_acc', \n",
    "                            verbose=1,\n",
    "                            save_best_only=True)\n",
    "                        ]\n",
    "                    )\n",
    "#------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, loss_ax = plt.subplots()\n",
    "\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(history.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(history.history['val_loss'], 'r', label='val loss')\n",
    "\n",
    "acc_ax.plot(history.history['accuracy'], 'b', label='train acc')\n",
    "acc_ax.plot(history.history['val_accuracy'], 'g', label='val acc')\n",
    "\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "acc_ax.set_ylabel('accuray')\n",
    "\n",
    "loss_ax.legend(loc='upper left')\n",
    "acc_ax.legend(loc='lower left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
