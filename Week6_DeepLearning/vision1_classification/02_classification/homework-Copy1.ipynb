{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cifar100 데이터셋 학습 (to do)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CIFAR-100 데이터셋은 총 100개의 label로 이루어진 이미지 분류를 위한 데이터셋이다.\n",
    "\n",
    "각각의 레이블마다 32×32 크기 이미지인 50,000개의 training 데이터셋, 10,000개의 test 데이터셋이 존재하고, 결과적으로 총 60,000개의 32×32 크기의 이미지로 데이터셋이 구성되어 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Physical GPUs, 2 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    " \n",
    " \n",
    " \n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) 데이터셋 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "from keras import datasets\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3) (50000, 1)\n",
      "(10000, 32, 32, 3) (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = datasets.cifar100.load_data()\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label :  [19]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f191807c5d0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('label : ',y_train[0])\n",
    "plt.imshow(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3) (50000, 100)\n",
      "(10000, 32, 32, 3) (10000, 100)\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "x_train_gray = np.dot(x_train[:,:,:,:3], [0.299, 0.587, 0.114])\n",
    "x_test_gray = np.dot(x_test[:,:,:,:3], [0.299, 0.587, 0.114])\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "\n",
    "x_train_gray = x_train_gray.reshape(-1,32,32,1)\n",
    "x_test_gray = x_test_gray.reshape(-1,32,32,1)\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) 모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "A `Concatenate` layer requires inputs with matching shapes except for the concat axis. Got inputs shapes: [(None, 32, 32, 64), (None, 11, 11, 128), (None, 7, 7, 32), (None, 32, 32, 32)]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-571be926833c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0minput_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'input'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m \u001b[0minception_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_inception_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m96\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0minception_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_inception_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minception_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m192\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m96\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-571be926833c>\u001b[0m in \u001b[0;36mbuild_inception_module\u001b[0;34m(input_layer, features_nr, module_nr, dropout, normalization, regularization, dropout_ratio)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0minception_pool_proj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_nr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'inception_%d_/pool_proj'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_nr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minception_pool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m     \u001b[0minception_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minception_1x1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minception_3x3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minception_5x5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minception_pool_proj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'inception_%d_/output'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_nr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/vision/lib/python3.7/site-packages/tensorflow/python/keras/layers/merge.py\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(inputs, axis, **kwargs)\u001b[0m\n\u001b[1;32m    925\u001b[0m       \u001b[0mA\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mconcatenation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minputs\u001b[0m \u001b[0malongside\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m   \"\"\"\n\u001b[0;32m--> 927\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mConcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    928\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/vision/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    895\u001b[0m           \u001b[0;31m# Build layer if applicable (if the `build` method has been\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m           \u001b[0;31m# overridden).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 897\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    898\u001b[0m           \u001b[0mcast_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/vision/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2414\u001b[0m         \u001b[0;31m# operations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2415\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_init_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2416\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2417\u001b[0m       \u001b[0;31m# We must set also ensure that the layer is marked as built, and the build\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2418\u001b[0m       \u001b[0;31m# shape is stored since user defined build functions may not be calling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/vision/lib/python3.7/site-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(instance, input_shape)\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m       \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_shapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_tuples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m     \u001b[0moutput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m     \u001b[0;31m# Return shapes from `fn` as TensorShapes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0moutput_shape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/vision/lib/python3.7/site-packages/tensorflow/python/keras/layers/merge.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    517\u001b[0m             shape[axis] for shape in shape_set if shape[axis] is not None)\n\u001b[1;32m    518\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munique_dims\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_merge_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: A `Concatenate` layer requires inputs with matching shapes except for the concat axis. Got inputs shapes: [(None, 32, 32, 64), (None, 11, 11, 128), (None, 7, 7, 32), (None, 32, 32, 32)]"
     ]
    }
   ],
   "source": [
    "np.random.seed(451)\n",
    "import datetime\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers import BatchNormalization, MaxPooling2D\n",
    "from keras.layers.core import Dense,Activation,Dropout,Flatten\n",
    "from keras.utils import np_utils\n",
    "from keras.layers.core import Lambda\n",
    "from keras import backend as K\n",
    "from keras import regularizers\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models, optimizers\n",
    "from keras.layers import Flatten, Activation, Conv2D, MaxPool2D, AvgPool2D, Dense, Dropout, BatchNormalization, Input, MaxPooling2D, Flatten, Activation, Conv2D, AvgPool2D, Dense, Dropout, concatenate, AveragePooling2D\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.models import Sequential\n",
    "import keras.backend as K\n",
    "from keras.regularizers import l1,l2\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n",
    "from keras.models import model_from_json, Model\n",
    "\n",
    "def build_tower(input_layer, features_nr, shape, tower_nr, \n",
    "                dropout=False, normalization=False, regularization=\"l2\", dropout_ratio=0.25):\n",
    "    #3x3 kernel tower\n",
    "    tower = Conv2D(features_nr, (1,1), padding='same', activation='relu', \n",
    "                     kernel_regularizer=regularization, name='tower_%d_%dx%da'%(tower_nr, shape[0], shape[1]))(input_layer)\n",
    "    tower = Conv2D(features_nr*2, shape, padding='same', activation='relu',\n",
    "                     kernel_regularizer=regularization, name='tower_%d_%dx%db'%(tower_nr, shape[0], shape[1]))(tower)\n",
    "    #condidional dropout/normalization\n",
    "    if dropout:\n",
    "        tower = Dropout(dropout_ratio, name='tower_%d_%dx%ddrop'%(tower_nr, shape[0], shape[1]))(tower)\n",
    "    if normalization:\n",
    "        tower = BatchNormalization(name='tower_%d_%dx%dnorm'%(tower_nr, shape[0], shape[1]))(tower)\n",
    "        \n",
    "    return tower\n",
    "\n",
    "def build_simple_tower(input_layer, features_nr, shape, tower_nr, \n",
    "                dropout=False, normalization=False, regularization=\"l2\", dropout_ratio=0.25):\n",
    "    #3x3 kernel tower\n",
    "    tower = Conv2D(features_nr, shape, padding='same', activation='relu',\n",
    "                     kernel_regularizer=regularization, \n",
    "                   name='tower_simple_%d_%dx%db'%(tower_nr, shape[0], shape[1]))(input_layer)\n",
    "    #condidional dropout/normalization\n",
    "    if dropout:\n",
    "        tower = Dropout(dropout_ratio, name='tower_%d_%dx%ddrop'%(tower_nr, shape[0], shape[1]))(tower)\n",
    "    if normalization:\n",
    "        tower = BatchNormalization(name='tower_%d_%dx%dnorm'%(tower_nr, shape[0], shape[1]))(tower)\n",
    "        \n",
    "    return tower\n",
    "\n",
    "def build_tower_subsample(input_layer, features_nr, shape, tower_nr, \n",
    "                          dropout=False, normalization=False, regularization='l2', dropout_ratio=0.25):\n",
    "    tower = build_tower(input_layer, features_nr, shape, tower_nr, \n",
    "                        dropout, normalization, regularization, dropout_ratio)\n",
    "    pool = MaxPooling2D((2,2), padding='same', name='tower_%d_2x2subsample'%(tower_nr))(tower)\n",
    "\n",
    "    return pool\n",
    "\n",
    "def build_simple_tower_subsample(input_layer, features_nr, shape, tower_nr, \n",
    "                          dropout=False, normalization=False, regularization='l2', dropout_ratio=0.25):\n",
    "    tower = build_simple_tower(input_layer, features_nr, shape, tower_nr, \n",
    "                        dropout, normalization, regularization, dropout_ratio)\n",
    "    pool = MaxPooling2D((2,2), padding='same', name='tower_%d_2x2subsample'%(tower_nr))(tower)\n",
    "\n",
    "    return pool\n",
    "\n",
    "def build_dense(input_layer, neurons_nr, dense_nr, \n",
    "                dropout=False, normalization=False, regularization='l2', dropout_ratio=0.5):\n",
    "    dense = Dense(neurons_nr, kernel_regularizer=regularization, \n",
    "                  name='dense_%d_%d'%(dense_nr, neurons_nr))(input_layer)\n",
    "    \n",
    "    if dropout:\n",
    "        dense = Dropout(dropout_ratio, name='dense_%d_%ddrop'%(dense_nr, neurons_nr))(dense)\n",
    "    if normalization:\n",
    "        dense = BatchNormalization(name='dense_%d_%dnorm'%(dense_nr, neurons_nr))(dense)\n",
    "    \n",
    "    return dense\n",
    "\n",
    "def build_inception_module(input_layer, features_nr, module_nr, \n",
    "                           dropout=False, normalization=False, regularization='l2', dropout_ratio=0.2):  \n",
    "    #feature_nr is an array we'll use to build our layers\n",
    "    #data is in the form: [1x1, 3x3 reduce, 3x3, 5x5 reduce, 5x5, pool proj]\n",
    "  \n",
    "    inception_1x1 = Conv2D(features_nr[0],1,1,padding='same',activation='relu',name='inception_%d_/1x1'%(module_nr))(input_layer)\n",
    "    \n",
    "    inception_3x3_reduce = Conv2D(features_nr[1],1,1,padding='same',activation='relu',name='inception_%d_/3x3_reduce'%(module_nr))(input_layer)\n",
    "    \n",
    "    inception_3x3 = Conv2D(features_nr[2],3,3,padding='same',activation='relu',name='inception_%d_/3x3'%(module_nr))(inception_3x3_reduce)\n",
    "    \n",
    "    inception_5x5_reduce = Conv2D(features_nr[3],1,1,padding='same',activation='relu',name='inception_%d_/5x5_reduce'%(module_nr))(input_layer)\n",
    "    \n",
    "    inception_5x5 = Conv2D(features_nr[4],5,5,padding='same',activation='relu',name='inception_%d_/5x5'%(module_nr))(inception_5x5_reduce)\n",
    "    \n",
    "    inception_pool = MaxPooling2D(pool_size=(3,3),strides=(1,1),padding='same',name='inception_%d_/pool'%(module_nr))(input_layer)\n",
    "    \n",
    "    inception_pool_proj = Conv2D(features_nr[5],1,1,padding='same',activation='relu',name='inception_%d_/pool_proj'%(module_nr))(inception_pool)\n",
    "    \n",
    "    inception_output = concatenate([inception_1x1,inception_3x3,inception_5x5,inception_pool_proj],axis=3,name='inception_%d_/output'%(module_nr))\n",
    "\n",
    "    if dropout:\n",
    "        inception_output = Dropout(dropout_ratio, name='inception_%d_/output_drop'%(module_nr))(inception_output)\n",
    "    if normalization:\n",
    "        inception_output = BatchNormalization(name='inception_%d_/output_norm'%(module_nr))(inception_output)\n",
    "\n",
    "    pooled = MaxPooling2D((2,2), padding='same', name='inception_%d_2x2subsample'%(module_nr))(inception_output)\n",
    "    \n",
    "    return pooled\n",
    "    \n",
    "    \n",
    "use_norm = True\n",
    "lrate = 0.001\n",
    "\n",
    "input_img = Input(shape = (32, 32, 3), name='input')\n",
    "\n",
    "inception_1 = build_inception_module(input_img, [64,96,128,16,32,32], 1, False, use_norm)\n",
    "\n",
    "inception_2 = build_inception_module(inception_1, [128,128,192,32,96,64], 2, False, use_norm)\n",
    "\n",
    "inception_3 = build_inception_module(inception_2, [192,96,208,16,48,64], 3, False, use_norm)\n",
    "\n",
    "inception_4 = build_inception_module(inception_3, [160, 112, 224, 24, 64, 64], 4, False, use_norm)\n",
    "\n",
    "flat_pool = AveragePooling2D(pool_size=(2, 2), padding='valid')(inception_4)\n",
    "\n",
    "flat = Flatten()(flat_pool)\n",
    "\n",
    "\n",
    "dense_5 = build_dense(flat, 128, 1, True, use_norm)\n",
    "\n",
    "dense_6 = build_dense(dense_5, 64, 2, True, use_norm)\n",
    "\n",
    "out = Dense(100, activation='softmax')(dense_6)\n",
    "\n",
    "model = Model(inputs = input_img, outputs = out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3) 모델의 학습과정 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = optimizers.SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer=sgd,loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 4, 4, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               51300     \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 100)               0         \n",
      "=================================================================\n",
      "Total params: 15,047,588\n",
      "Trainable params: 15,038,116\n",
      "Non-trainable params: 9,472\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (4) 모델 학습시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "391/391 [==============================] - 73s 187ms/step - loss: 6.9348 - accuracy: 0.0264\n",
      "Epoch 2/100\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 6.1647 - accuracy: 0.0426\n",
      "Epoch 3/100\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 5.9074 - accuracy: 0.0504\n",
      "Epoch 4/100\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 5.6931 - accuracy: 0.0600\n",
      "Epoch 5/100\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 5.4950 - accuracy: 0.0720\n",
      "Epoch 6/100\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 5.2994 - accuracy: 0.0843\n",
      "Epoch 7/100\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 5.1121 - accuracy: 0.0985\n",
      "Epoch 8/100\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 4.9314 - accuracy: 0.1128\n",
      "Epoch 9/100\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 4.7676 - accuracy: 0.1277\n",
      "Epoch 10/100\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 4.6321 - accuracy: 0.1373\n",
      "Epoch 11/100\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 4.4801 - accuracy: 0.1520\n",
      "Epoch 12/100\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 4.3267 - accuracy: 0.1731\n",
      "Epoch 13/100\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 4.1771 - accuracy: 0.1868\n",
      "Epoch 14/100\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 4.0190 - accuracy: 0.2112\n",
      "Epoch 15/100\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 3.8498 - accuracy: 0.2347\n",
      "Epoch 16/100\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 3.6972 - accuracy: 0.2570\n",
      "Epoch 17/100\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 3.5437 - accuracy: 0.2844\n",
      "Epoch 18/100\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 3.4063 - accuracy: 0.3097\n",
      "Epoch 19/100\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 3.2732 - accuracy: 0.3306\n",
      "Epoch 20/100\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 3.1570 - accuracy: 0.3555\n",
      "Epoch 21/100\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 3.0523 - accuracy: 0.3788\n",
      "Epoch 22/100\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 2.9683 - accuracy: 0.3965\n",
      "Epoch 23/100\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 2.9106 - accuracy: 0.4109\n",
      "Epoch 24/100\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 2.8238 - accuracy: 0.4300\n",
      "Epoch 25/100\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 2.7547 - accuracy: 0.4465\n",
      "Epoch 26/100\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 2.7047 - accuracy: 0.4611\n",
      "Epoch 27/100\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 2.6596 - accuracy: 0.4757\n",
      "Epoch 28/100\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 2.5986 - accuracy: 0.4909\n",
      "Epoch 29/100\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 2.5502 - accuracy: 0.5062\n",
      "Epoch 30/100\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 2.5269 - accuracy: 0.5148\n",
      "Epoch 31/100\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 2.5007 - accuracy: 0.5241\n",
      "Epoch 32/100\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 2.4633 - accuracy: 0.5371\n",
      "Epoch 33/100\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 2.4310 - accuracy: 0.5528\n",
      "Epoch 34/100\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 2.4077 - accuracy: 0.5588\n",
      "Epoch 35/100\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 2.3968 - accuracy: 0.5676\n",
      "Epoch 36/100\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 2.3771 - accuracy: 0.5758\n",
      "Epoch 37/100\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 2.3736 - accuracy: 0.5846\n",
      "Epoch 38/100\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 2.3517 - accuracy: 0.5927\n",
      "Epoch 39/100\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 2.3424 - accuracy: 0.6000\n",
      "Epoch 40/100\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 2.3356 - accuracy: 0.6099\n",
      "Epoch 41/100\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 2.3223 - accuracy: 0.6183\n",
      "Epoch 42/100\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 2.3118 - accuracy: 0.6246\n",
      "Epoch 43/100\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 2.3093 - accuracy: 0.6287\n",
      "Epoch 44/100\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 2.3073 - accuracy: 0.6340\n",
      "Epoch 45/100\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 2.2986 - accuracy: 0.6417\n",
      "Epoch 46/100\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 2.2966 - accuracy: 0.6479\n",
      "Epoch 47/100\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 2.3180 - accuracy: 0.6497\n",
      "Epoch 48/100\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 2.3062 - accuracy: 0.6590\n",
      "Epoch 49/100\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 2.2975 - accuracy: 0.6673\n",
      "Epoch 50/100\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 2.2913 - accuracy: 0.6703\n",
      "Epoch 51/100\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 2.2936 - accuracy: 0.6751\n",
      "Epoch 52/100\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 2.3000 - accuracy: 0.6790\n",
      "Epoch 53/100\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 2.3053 - accuracy: 0.6812\n",
      "Epoch 54/100\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 2.2992 - accuracy: 0.6887\n",
      "Epoch 55/100\n",
      "391/391 [==============================] - 17s 42ms/step - loss: 2.3111 - accuracy: 0.6900\n",
      "Epoch 56/100\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 2.2994 - accuracy: 0.7002\n",
      "Epoch 57/100\n",
      "391/391 [==============================] - 16s 42ms/step - loss: 2.3031 - accuracy: 0.7004\n",
      "Epoch 58/100\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 2.3190 - accuracy: 0.7015\n",
      "Epoch 59/100\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 2.3194 - accuracy: 0.7065\n",
      "Epoch 60/100\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 2.3219 - accuracy: 0.7103\n",
      "Epoch 61/100\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 2.3300 - accuracy: 0.7121\n",
      "Epoch 62/100\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 2.3381 - accuracy: 0.7145\n",
      "Epoch 63/100\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 2.3234 - accuracy: 0.7216\n",
      "Epoch 64/100\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 2.3323 - accuracy: 0.7235\n",
      "Epoch 65/100\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 2.3473 - accuracy: 0.7254\n",
      "Epoch 66/100\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 2.3369 - accuracy: 0.7312\n",
      "Epoch 67/100\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 2.3403 - accuracy: 0.7335\n",
      "Epoch 68/100\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 2.3493 - accuracy: 0.7356\n",
      "Epoch 69/100\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 2.3482 - accuracy: 0.7396\n",
      "Epoch 70/100\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 2.3590 - accuracy: 0.7381\n",
      "Epoch 71/100\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 2.3574 - accuracy: 0.7442\n",
      "Epoch 72/100\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 2.3673 - accuracy: 0.7416\n",
      "Epoch 73/100\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 2.3678 - accuracy: 0.7482\n",
      "Epoch 74/100\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 2.3755 - accuracy: 0.7498\n",
      "Epoch 75/100\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 2.3732 - accuracy: 0.7523\n",
      "Epoch 76/100\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 2.3801 - accuracy: 0.7527\n",
      "Epoch 77/100\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 2.3725 - accuracy: 0.7582\n",
      "Epoch 78/100\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 2.3829 - accuracy: 0.7563\n",
      "Epoch 79/100\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 2.3840 - accuracy: 0.7592\n",
      "Epoch 80/100\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 2.3810 - accuracy: 0.7617\n",
      "Epoch 81/100\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 2.3795 - accuracy: 0.7641\n",
      "Epoch 82/100\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 2.3755 - accuracy: 0.7680\n",
      "Epoch 83/100\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 2.3951 - accuracy: 0.7641\n",
      "Epoch 84/100\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 2.3856 - accuracy: 0.7716\n",
      "Epoch 85/100\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 2.4016 - accuracy: 0.7675\n",
      "Epoch 86/100\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 2.3916 - accuracy: 0.7746\n",
      "Epoch 87/100\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 2.4021 - accuracy: 0.7736\n",
      "Epoch 88/100\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 2.4006 - accuracy: 0.7738\n",
      "Epoch 89/100\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 2.4040 - accuracy: 0.7773\n",
      "Epoch 90/100\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 2.4063 - accuracy: 0.7771\n",
      "Epoch 91/100\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 2.4075 - accuracy: 0.7788\n",
      "Epoch 92/100\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 2.4063 - accuracy: 0.7813\n",
      "Epoch 93/100\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 2.4150 - accuracy: 0.7813\n",
      "Epoch 94/100\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 2.4097 - accuracy: 0.7844\n",
      "Epoch 95/100\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 2.4244 - accuracy: 0.7822\n",
      "Epoch 96/100\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 2.4092 - accuracy: 0.7885\n",
      "Epoch 97/100\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 2.4114 - accuracy: 0.7906\n",
      "Epoch 98/100\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 2.4234 - accuracy: 0.7867\n",
      "Epoch 99/100\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 2.4162 - accuracy: 0.7919\n",
      "Epoch 100/100\n",
      "391/391 [==============================] - 17s 43ms/step - loss: 2.4172 - accuracy: 0.7911\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,Y_train,batch_size=128, epochs=100,verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (5) 모델 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 4s 8ms/step - loss: 3.4533 - accuracy: 0.6115\n",
      "loss :  61.15000247955322 %\n"
     ]
    }
   ],
   "source": [
    "result= model.evaluate(X_test, Y_test, batch_size=20)\n",
    "print('loss : ',result[1]*100,\"%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
